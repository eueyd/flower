import os
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from tqdm import tqdm
import gc

from config import *
from model_components import ImprovedDualPathModel


def train_model(device, model_path=MODEL_PATH, metrics_path=METRICS_PATH):
    """è®­ç»ƒæ¨¡å‹"""
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒåŒè·¯å¾„æ¨¡å‹...")

    # æ¸…ç†ç¼“å­˜
    torch.cuda.empty_cache()
    gc.collect()

    # åŠ è½½æ•°æ®
    from data_loader import create_data_loaders
    train_loader, test_loader, train_dataset, test_dataset = create_data_loaders()

    print(f"è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
    print(f"æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")

    # æ„å»ºæ¨¡å‹
    print(f"\nğŸ”§ æ„å»ºæ¨¡å‹...")
    model = ImprovedDualPathModel(
        num_classes=NUM_CLASSES,
        num_regions=NUM_REGIONS
    )
    model = model.to(device)

    # ç»Ÿè®¡å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"æ¨¡å‹å‚æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,}")
    print(f"å†»ç»“å‚æ•°é‡: {total_params - trainable_params:,}")

    # ä¼˜åŒ–å™¨
    optimizer = optim.Adam(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=0.0001,
        weight_decay=1e-5
    )
    # warmup_epochs = 3  # é¢„çƒ­1ä¸ªepochï¼ˆçº¦63ä¸ªbatchï¼‰
    # warmup_factor = 10.0  # é¢„çƒ­æœŸå­¦ä¹ ç‡æ”¾å¤§10å€ï¼ˆ1e-3 â†’ 1e-2ï¼‰

    # def warmup_lr_scheduler(epoch, batch_idx, total_batches):
    #     """åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡"""
    #     total_warmup_steps = warmup_epochs * total_batches  # æ€»å…±çš„é¢„çƒ­æ­¥æ•°
    #     current_step = epoch * total_batches + batch_idx
    #
    #     if current_step < total_warmup_steps:
    #         # çº¿æ€§é¢„çƒ­ï¼šä»0åˆ°1e-2
    #         alpha = current_step / total_warmup_steps
    #         warmup_lr = LEARNING_RATE * warmup_factor * alpha
    #         for param_group in optimizer.param_groups:
    #             param_group['lr'] = warmup_lr
    #     else:
            # é¢„çƒ­ç»“æŸï¼Œä½¿ç”¨æ­£å¸¸å­¦ä¹ ç‡
            # for param_group in optimizer.param_groups:
            #     param_group['lr'] = LEARNING_RATE



    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.93)

    # æŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss()

    # è®­ç»ƒæŒ‡æ ‡
    train_losses = []
    train_accs = []
    test_losses = []
    test_accs = []
    best_test_acc = 0.0

    print(f"\nğŸ“ˆ å¼€å§‹è®­ç»ƒï¼Œå…± {EPOCHS} ä¸ªepoch...")

    for epoch in range(EPOCHS):
        # ===== è®­ç»ƒé˜¶æ®µ =====
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        fusion_stats = []

        pbar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{EPOCHS} [Train]")
        for batch_idx, (images, labels) in enumerate(pbar):
            # å®šæœŸæ¸…ç†ç¼“å­˜
            if batch_idx % 20 == 0:
                torch.cuda.empty_cache()

            images, labels = images.to(device), labels.to(device)

            # å‰å‘ä¼ æ’­
            outputs = model(images)

            # è®¡ç®—æŸå¤±
            loss, loss_details = model.compute_loss(outputs, labels, criterion)

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(
                filter(lambda p: p.requires_grad, model.parameters()),
                max_norm=0.5
            )

            optimizer.step()

            # ç»Ÿè®¡
            running_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs['final_logits'], 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            # æ”¶é›†èåˆæƒé‡
            if 'fusion_weights' in outputs:
                fusion_stats.append(outputs['fusion_weights'].mean(dim=0).cpu().detach().numpy())

            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                "loss": running_loss / max(total, 1),
                "acc": correct / max(total, 1),
                **{k: v for k, v in loss_details.items() if 'loss' in k}
            })

        train_loss = running_loss / len(train_loader.dataset)
        train_acc = correct / total

        # ===== éªŒè¯é˜¶æ®µ =====
        model.eval()
        running_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            pbar = tqdm(test_loader, desc=f"Epoch {epoch + 1}/{EPOCHS} [Val]")
            for images, labels in pbar:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)

                loss = criterion(outputs['final_logits'], labels)

                running_loss += loss.item() * images.size(0)
                _, predicted = torch.max(outputs['final_logits'], 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

                pbar.set_postfix({
                    "loss": running_loss / max(total, 1),
                    "acc": correct / max(total, 1)
                })

        test_loss = running_loss / len(test_loader.dataset)
        test_acc = correct / total

        # å­¦ä¹ ç‡è°ƒæ•´
        scheduler.step()

        # è®°å½•æŒ‡æ ‡
        train_losses.append(train_loss)
        train_accs.append(train_acc)
        test_losses.append(test_loss)
        test_accs.append(test_acc)

        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š Epoch {epoch + 1} ç»“æœ:")
        print(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}")
        print(f"  æµ‹è¯•æŸå¤±: {test_loss:.4f}, æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
        print(f"  å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.6f}")

        # ä¿å­˜æœ€ä¼˜æ¨¡å‹
        if test_acc > best_test_acc:
            best_test_acc = test_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_test_acc': best_test_acc,
                'config': {
                    'model_type': 'improved_dual_path',
                    'num_regions': NUM_REGIONS,
                    'image_size': IMAGE_SIZE,
                    'batch_size': BATCH_SIZE,
                    'num_classes': NUM_CLASSES
                }
            }, model_path)
            print(f"  ğŸ’¾ ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼Œå‡†ç¡®ç‡: {best_test_acc:.4f}")

    # ä¿å­˜è®­ç»ƒæŒ‡æ ‡
    metrics = {
        'train_losses': train_losses,
        'train_accs': train_accs,
        'test_losses': test_losses,
        'test_accs': test_accs,
        'best_test_acc': best_test_acc,
        'epochs': EPOCHS
    }
    np.save(metrics_path, metrics)

    print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
    print(f"æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡: {best_test_acc:.4f}")

    return model, train_losses, train_accs, test_losses, test_accs


def test_model(device, model_path=MODEL_PATH):
    """æµ‹è¯•æ¨¡å‹"""
    if not os.path.exists(model_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {model_path}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼")
        return

    print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹...")

    # åŠ è½½æ•°æ®
    from data_loader import create_data_loaders
    _, test_loader, _, test_dataset = create_data_loaders()

    # æ„å»ºæ¨¡å‹
    model = ImprovedDualPathModel(
        num_classes=NUM_CLASSES,
        num_regions=NUM_REGIONS
    )
    model = model.to(device)

    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()

    # æµ‹è¯•è¯„ä¼°
    criterion = nn.CrossEntropyLoss()
    running_loss = 0.0
    correct = 0
    total = 0

    print(f"å¼€å§‹æµ‹è¯•...")

    with torch.no_grad():
        pbar = tqdm(test_loader, desc="æµ‹è¯•ä¸­")
        for images, labels in pbar:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)

            # è®¡ç®—æŸå¤±
            loss = criterion(outputs['final_logits'], labels)

            # ç»Ÿè®¡æŒ‡æ ‡
            running_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs['final_logits'], 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            pbar.set_postfix({
                "acc": correct / max(total, 1)
            })

    # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
    final_loss = running_loss / len(test_loader.dataset)
    final_acc = correct / total

    print(f"\nğŸ“ˆ æµ‹è¯•ç»“æœ:")
    print(f"æµ‹è¯•æŸå¤±: {final_loss:.4f}")
    print(f"æµ‹è¯•å‡†ç¡®ç‡: {final_acc:.4f}")
    print(f"æœ€ä½³å†å²å‡†ç¡®ç‡: {checkpoint.get('best_test_acc', 0.0):.4f}")

    return final_acc


def load_pretrained_model(model, pretrained_path, freeze_backbone=FREEZE_BACKBONE):
    """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æƒé‡"""
    print(f"ğŸ”§ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {pretrained_path}")

    try:
        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        pretrained_state = torch.load(pretrained_path, map_location=DEVICE)

        # è·å–é¢„è®­ç»ƒæ¨¡å‹çš„state_dict
        if 'model_state_dict' in pretrained_state:
            pretrained_dict = pretrained_state['model_state_dict']
        else:
            pretrained_dict = pretrained_state

        # å½“å‰æ¨¡å‹state_dict
        model_dict = model.state_dict()

        # è¿‡æ»¤å¯ä»¥åŠ è½½çš„å‚æ•°
        pretrained_dict = {k: v for k, v in pretrained_dict.items()
                           if k in model_dict and v.shape == model_dict[k].shape}

        # æ›´æ–°å½“å‰æ¨¡å‹å‚æ•°
        model_dict.update(pretrained_dict)
        model.load_state_dict(model_dict)

        print(f"âœ… åŠ è½½äº† {len(pretrained_dict)}/{len(model_dict)} ä¸ªå‚æ•°")

        # å†»ç»“éª¨å¹²ç½‘ç»œ
        if freeze_backbone:
            freeze_parameters = [
                'conv1', 'bn1', 'layer1', 'layer2', 'layer3', 'layer4'
            ]

            for name, param in model.named_parameters():
                if any(freeze_name in name for freeze_name in freeze_parameters):
                    param.requires_grad = False
                    print(f"  â„ï¸ å†»ç»“: {name}")

        return model

    except Exception as e:
        print(f"âŒ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å¤±è´¥: {e}")
        return model


# def train_model_with_pretrain(device, model_path=MODEL_PATH,
#                               metrics_path=METRICS_PATH):
#     """ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè®­ç»ƒ"""
#     print(f"\nğŸš€ å¼€å§‹è®­ç»ƒï¼ˆä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰...")
#
#     # æ¸…ç†ç¼“å­˜
#     torch.cuda.empty_cache()
#     gc.collect()
#
#     # åŠ è½½æ•°æ®
#     from data_loader import create_data_loaders
#     train_loader, test_loader, train_dataset, test_dataset = create_data_loaders()
#
#     print(f"è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
#     print(f"æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
#
#     # æ„å»ºæ¨¡å‹
#     print(f"\nğŸ”§ æ„å»ºæ¨¡å‹...")
#     model = ImprovedDualPathModel(
#         num_classes=NUM_CLASSES,
#         num_regions=NUM_REGIONS,
#         backbone_name=BACKBONE_NAME  # ç¡®ä¿ä¸é¢„è®­ç»ƒæ¨¡å‹ä¸€è‡´
#     )
#     model = model.to(device)
#
#     # åŠ è½½é¢„è®­ç»ƒæƒé‡
#     from config import PRETRAINED_MODEL_PATH, FREEZE_BACKBONE
#     model = load_pretrained_model(model, PRETRAINED_MODEL_PATH, FREEZE_BACKBONE)
#
#     # ç»Ÿè®¡å‚æ•°
#     total_params = sum(p.numel() for p in model.parameters())
#     trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
#
#     print(f"\nğŸ“Š å‚æ•°ç»Ÿè®¡:")
#     print(f"æ€»å‚æ•°é‡: {total_params:,}")
#     print(f"å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,}")
#     print(f"è®­ç»ƒæ¯”ä¾‹: {trainable_params / total_params * 100:.1f}%")
#
#     # åˆ†å±‚å­¦ä¹ ç‡ä¼˜åŒ–å™¨
#     base_lr = LEARNING_RATE * FINETUNE_RATIO if FREEZE_BACKBONE else LEARNING_RATE
#
#     # ä¸ºä¸åŒå±‚è®¾ç½®ä¸åŒå­¦ä¹ ç‡
#     param_groups = []
#
#     # éª¨å¹²ç½‘ç»œå‚æ•°ï¼ˆå¦‚æœæœ‰æœªå†»ç»“çš„ï¼‰
#     backbone_params = []
#     # æ–°æ·»åŠ çš„æ¨¡å—å‚æ•°
#     new_params = []
#
#     for name, param in model.named_parameters():
#         if param.requires_grad:
#             if any(module in name for module in [
#                 'region_proposal', 'feature_fusion',
#                 'region_feature_enhancer', 'adaptive_fusion',
#                 'global_classifier', 'final_classifier',
#                 'region_classifiers'
#             ]):
#                 new_params.append(param)
#             else:
#                 backbone_params.append(param)
#
#     if backbone_params:
#         param_groups.append({
#             'params': backbone_params,
#             'lr': base_lr,  # è¾ƒä½çš„å­¦ä¹ ç‡
#             'weight_decay': 1e-4
#         })
#
#     if new_params:
#         param_groups.append({
#             'params': new_params,
#             'lr': LEARNING_RATE,  # æ­£å¸¸å­¦ä¹ ç‡
#             'weight_decay': 1e-3
#         })
#
#     if not param_groups:
#         # å¦‚æœæ‰€æœ‰å‚æ•°éƒ½è¢«å†»ç»“ï¼Œè§£å†»ä¸€äº›å±‚
#         print("âš ï¸ æ‰€æœ‰å‚æ•°è¢«å†»ç»“ï¼Œè§£å†»éƒ¨åˆ†å±‚...")
#         for name, param in model.named_parameters():
#             if 'final_classifier' in name or 'global_classifier' in name:
#                 param.requires_grad = True
#                 new_params.append(param)
#
#         param_groups.append({
#             'params': new_params,
#             'lr': LEARNING_RATE,
#             'weight_decay': 1e-3
#         })
#
#     optimizer = optim.Adam(param_groups)
#
#     # å­¦ä¹ ç‡è°ƒåº¦å™¨
#     scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
#         optimizer,
#         T_0=10,  # åˆå§‹å‘¨æœŸ
#         T_mult=2,  # å‘¨æœŸå€å¢
#         eta_min=base_lr * 0.01  # æœ€å°å­¦ä¹ ç‡
#     )
#
#     # æŸå¤±å‡½æ•°
#     criterion = nn.CrossEntropyLoss()
#
#     # è®­ç»ƒæŒ‡æ ‡
#     train_losses, train_accs = [], []
#     test_losses, test_accs = [], []
#     best_test_acc = 0.0
#
#     print(f"\nğŸ“ˆ å¼€å§‹è®­ç»ƒï¼Œå…± {EPOCHS} ä¸ªepoch...")
#     print(f"åŸºç¡€å­¦ä¹ ç‡: {base_lr:.6f}")
#     print(f"æ–°å¢æ¨¡å—å­¦ä¹ ç‡: {LEARNING_RATE:.6f}")
#
#     for epoch in range(EPOCHS):
#         # ===== è®­ç»ƒé˜¶æ®µ =====
#         model.train()
#         running_loss = 0.0
#         correct = 0
#         total = 0
#
#         pbar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{EPOCHS} [Train]")
#         for batch_idx, (images, labels) in enumerate(pbar):
#             # å®šæœŸæ¸…ç†ç¼“å­˜
#             if batch_idx % 20 == 0:
#                 torch.cuda.empty_cache()
#
#             images, labels = images.to(device), labels.to(device)
#
#             # å‰å‘ä¼ æ’­
#             outputs = model(images)
#
#             # è®¡ç®—æŸå¤±
#             loss, loss_details = model.compute_loss(outputs, labels, criterion)
#
#             # åå‘ä¼ æ’­
#             optimizer.zero_grad()
#             loss.backward()
#
#             # æ¢¯åº¦è£å‰ª
#             torch.nn.utils.clip_grad_norm_(
#                 model.parameters(),
#                 max_norm=0.5
#             )
#
#             optimizer.step()
#
#             # ç»Ÿè®¡
#             running_loss += loss.item() * images.size(0)
#             _, predicted = torch.max(outputs['final_logits'], 1)
#             total += labels.size(0)
#             correct += (predicted == labels).sum().item()
#
#             # æ›´æ–°è¿›åº¦æ¡
#             pbar.set_postfix({
#                 "loss": running_loss / max(total, 1),
#                 "acc": correct / max(total, 1),
#                 **{k: v for k, v in loss_details.items() if 'loss' in k}
#             })
#
#         train_loss = running_loss / len(train_loader.dataset)
#         train_acc = correct / total
#
#         # ===== éªŒè¯é˜¶æ®µ =====
#         model.eval()
#         running_loss = 0.0
#         correct = 0
#         total = 0
#
#         with torch.no_grad():
#             pbar = tqdm(test_loader, desc=f"Epoch {epoch + 1}/{EPOCHS} [Val]")
#             for images, labels in pbar:
#                 images, labels = images.to(device), labels.to(device)
#                 outputs = model(images)
#
#                 loss = criterion(outputs['final_logits'], labels)
#
#                 running_loss += loss.item() * images.size(0)
#                 _, predicted = torch.max(outputs['final_logits'], 1)
#                 total += labels.size(0)
#                 correct += (predicted == labels).sum().item()
#
#                 pbar.set_postfix({
#                     "loss": running_loss / max(total, 1),
#                     "acc": correct / max(total, 1)
#                 })
#
#         test_loss = running_loss / len(test_loader.dataset)
#         test_acc = correct / total
#
#         # å­¦ä¹ ç‡è°ƒæ•´
#         scheduler.step()
#
#         # è®°å½•æŒ‡æ ‡
#         train_losses.append(train_loss)
#         train_accs.append(train_acc)
#         test_losses.append(test_loss)
#         test_accs.append(test_acc)
#
#         # æ‰“å°ç»“æœ
#         print(f"\nğŸ“Š Epoch {epoch + 1} ç»“æœ:")
#         print(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}")
#         print(f"  æµ‹è¯•æŸå¤±: {test_loss:.4f}, æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
#
#         # é€æ­¥è§£å†»ç­–ç•¥
#         if epoch == 10 and FREEZE_BACKBONE:  # 10ä¸ªepochåè§£å†»éƒ¨åˆ†å±‚
#             print(f"  ğŸ”“ é€æ­¥è§£å†»layer4...")
#             for name, param in model.named_parameters():
#                 if 'layer4' in name and param.requires_grad == False:
#                     param.requires_grad = True
#                     print(f"    è§£å†»: {name}")
#
#         # ä¿å­˜æœ€ä¼˜æ¨¡å‹
#         if test_acc > best_test_acc:
#             best_test_acc = test_acc
#             torch.save({
#                 'epoch': epoch,
#                 'model_state_dict': model.state_dict(),
#                 'optimizer_state_dict': optimizer.state_dict(),
#                 'scheduler_state_dict': scheduler.state_dict(),
#                 'best_test_acc': best_test_acc,
#                 'train_acc': train_acc,
#                 'test_acc': test_acc,
#                 'config': {
#                     'model_type': 'improved_dual_path_pretrained',
#                     'pretrained_path': PRETRAINED_MODEL_PATH,
#                     'freeze_backbone': FREEZE_BACKBONE,
#                     'num_regions': NUM_REGIONS,
#                     'backbone': BACKBONE_NAME,
#                     'num_classes': NUM_CLASSES
#                 }
#             }, model_path)
#             print(f"  ğŸ’¾ ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼Œå‡†ç¡®ç‡: {best_test_acc:.4f}")
#
#     # ä¿å­˜è®­ç»ƒæŒ‡æ ‡
#     metrics = {
#         'train_losses': train_losses,
#         'train_accs': train_accs,
#         'test_losses': test_losses,
#         'test_accs': test_accs,
#         'best_test_acc': best_test_acc,
#         'epochs': EPOCHS
#     }
#     np.save(metrics_path, metrics)
#
#     print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
#     print(f"æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡: {best_test_acc:.4f}")
#
#     return model, train_losses, train_accs, test_losses, test_accs


def train_model_with_pretrain(device):
    """ä¿®å¤çš„é¢„è®­ç»ƒæ¨¡å‹è®­ç»ƒ"""
    print(f"\nğŸš€ ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆä½œä¸ºç‰¹å¾æå–å™¨ï¼‰...")

    # æ„å»ºç®€åŒ–æ¨¡å‹
    from torchvision import models
    import torch.nn as nn

    # ç›´æ¥ä½¿ç”¨é¢„è®­ç»ƒçš„ResNet50
    pretrained_model = models.resnet50(pretrained=False)
    num_ftrs = pretrained_model.fc.in_features

    # åŠ è½½ä½ çš„é¢„è®­ç»ƒæƒé‡
    checkpoint = torch.load("model_89.pth", map_location=device)
    if 'model_state_dict' in checkpoint:
        pretrained_model.load_state_dict(checkpoint['model_state_dict'])
    else:
        pretrained_model.load_state_dict(checkpoint)

    print(f"âœ… åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œå‡†ç¡®ç‡89%")

    # å†»ç»“æ‰€æœ‰å±‚
    for param in pretrained_model.parameters():
        param.requires_grad = False

    # åªè®­ç»ƒæœ€åçš„åˆ†ç±»å±‚ï¼ˆé€‚é…ä½ çš„102ç±»ï¼‰
    pretrained_model.fc = nn.Sequential(
        nn.Linear(num_ftrs, 512),
        nn.ReLU(),
        nn.Dropout(0.5),
        nn.Linear(512, NUM_CLASSES)
    )

    pretrained_model = pretrained_model.to(device)

    # è®­ç»ƒ
    optimizer = torch.optim.Adam(pretrained_model.fc.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()

    from data_loader import create_data_loaders
    train_loader, test_loader, _, _ = create_data_loaders()

    train_losses, train_accs = [], []
    test_losses, test_accs = [], []

    for epoch in range(5):  # å°‘é‡epoch
        # è®­ç»ƒ
        pretrained_model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = pretrained_model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        train_acc = correct / total
        train_loss = running_loss / len(train_loader)
        train_losses.append(train_loss)
        train_accs.append(train_acc)

        # æµ‹è¯•
        pretrained_model.eval()
        running_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = pretrained_model(images)
                loss = criterion(outputs, labels)

                running_loss += loss.item()
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        test_acc = correct / total
        test_loss = running_loss / len(test_loader)
        test_losses.append(test_loss)
        test_accs.append(test_acc)

        print(f"Epoch {epoch + 1}: Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}")

    return pretrained_model, train_losses, train_accs, test_losses, test_accs

def create_exact_resnet50_model(device):
    """åˆ›å»ºä¸model_89.pthå®Œå…¨åŒ¹é…çš„ResNet50æ¨¡å‹"""
    from torchvision import models
    import torch.nn as nn

    print("ğŸ”§ åˆ›å»ºå®Œå…¨åŒ¹é…çš„ResNet50æ¨¡å‹...")

    # åˆ›å»ºæ ‡å‡†ResNet50ï¼ˆä¸è¦é¢„è®­ç»ƒæƒé‡ï¼‰
    model = models.resnet50(weights=None)

    # ä¿®æ”¹å…¨è¿æ¥å±‚ä»¥å®Œå…¨åŒ¹é…ä½ çš„ç»“æ„
    print("ğŸ”§ ä¿®æ”¹å…¨è¿æ¥å±‚ä»¥åŒ¹é…é¢„è®­ç»ƒæ¨¡å‹...")

    # ä½ çš„fcå±‚ç»“æ„ï¼š2048 â†’ 1024 â†’ 512 â†’ 102
    model.fc = nn.Sequential(
        nn.Linear(2048, 1024),  # fc.0
        nn.ReLU(inplace=True),
        nn.Dropout(0.6),
        nn.Linear(1024, 512),  # fc.3
        nn.ReLU(inplace=True),
        nn.Dropout(0.5),
        nn.Linear(512, 102)  # fc.6
    )

    # åŠ è½½é¢„è®­ç»ƒæƒé‡
    print("ğŸ“¥ åŠ è½½é¢„è®­ç»ƒæƒé‡...")
    checkpoint = torch.load("model_89.pth", map_location=device)

    # ç›´æ¥åŠ è½½ï¼ˆåº”è¯¥å®Œå…¨åŒ¹é…ï¼‰
    model.load_state_dict(checkpoint, strict=True)

    print("âœ… æƒé‡åŠ è½½æˆåŠŸï¼å®Œå…¨åŒ¹é…")

    model = model.to(device)

    # éªŒè¯æ¨¡å‹
    print("\nğŸ¯ æ¨¡å‹éªŒè¯:")
    print(f"éª¨å¹²ç½‘ç»œ: ResNet50")
    print(f"ç‰¹å¾ç»´åº¦: 2048")
    print(f"åˆ†ç±»å™¨ç»“æ„: 2048 â†’ 1024 â†’ 512 â†’ 102")

    # æµ‹è¯•å‰å‘ä¼ æ’­
    model.eval()
    with torch.no_grad():
        test_input = torch.randn(2, 3, 224, 224).to(device)
        output = model(test_input)
        print(f"æµ‹è¯•è¾“å…¥: {test_input.shape}")
        print(f"æµ‹è¯•è¾“å‡º: {output.shape}")
        print(f"è¾“å‡ºç»´åº¦: {output.shape[1]} (åº”è¯¥æ˜¯102)")

    return model


def finetune_resnet50(device, freeze_backbone=True):
    """å¾®è°ƒResNet50æ¨¡å‹"""
    print(f"\nğŸš€ å¼€å§‹å¾®è°ƒResNet50æ¨¡å‹...")

    # åˆ›å»ºå®Œå…¨åŒ¹é…çš„æ¨¡å‹
    model = create_exact_resnet50_model(device)

    # å†»ç»“ç­–ç•¥
    if freeze_backbone:
        print("\nğŸ”’ å†»ç»“éª¨å¹²ç½‘ç»œ...")
        frozen_count = 0
        trainable_count = 0

        for name, param in model.named_parameters():
            if 'fc' in name:  # åªè®­ç»ƒå…¨è¿æ¥å±‚
                param.requires_grad = True
                trainable_count += 1
                print(f"  ğŸ”“ è®­ç»ƒ: {name}")
            else:
                param.requires_grad = False
                frozen_count += 1

        print(f"\nğŸ“Š å†»ç»“ç»Ÿè®¡:")
        print(f"å†»ç»“å‚æ•°: {frozen_count} ä¸ªå±‚")
        print(f"å¯è®­ç»ƒå‚æ•°: {trainable_count} ä¸ªå±‚")
    else:
        print("\nğŸ”“ è§£å†»æ‰€æœ‰å±‚è¿›è¡Œè®­ç»ƒ...")
        for param in model.parameters():
            param.requires_grad = True

    # åŠ è½½æ•°æ®
    from data_loader import create_data_loaders
    train_loader, test_loader, train_dataset, test_dataset = create_data_loaders()

    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")

    # ä¼˜åŒ–å™¨
    if freeze_backbone:
        # åªä¼˜åŒ–å…¨è¿æ¥å±‚
        optimizer = torch.optim.Adam(
            model.fc.parameters(),
            lr=0.001,  # è¾ƒå°å­¦ä¹ ç‡
            weight_decay=1e-4
        )
    else:
        # ä¼˜åŒ–æ‰€æœ‰å‚æ•°ï¼Œä½†åˆ†å±‚å­¦ä¹ ç‡
        optimizer = torch.optim.Adam([
            {'params': model.conv1.parameters(), 'lr': 0.0001},
            {'params': model.bn1.parameters(), 'lr': 0.0001},
            {'params': model.layer1.parameters(), 'lr': 0.0001},
            {'params': model.layer2.parameters(), 'lr': 0.0001},
            {'params': model.layer3.parameters(), 'lr': 0.0001},
            {'params': model.layer4.parameters(), 'lr': 0.0001},
            {'params': model.fc.parameters(), 'lr': 0.001}
        ], weight_decay=1e-4)

    # æŸå¤±å‡½æ•°
    criterion = torch.nn.CrossEntropyLoss()

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)

    # è®­ç»ƒå¾ªç¯
    train_losses, train_accs = [], []
    test_losses, test_accs = [], []
    best_acc = 0.0

    epochs = 20
    print(f"\nğŸ“ˆ å¼€å§‹è®­ç»ƒï¼Œå…± {epochs} ä¸ªepoch...")

    for epoch in range(epochs):
        # è®­ç»ƒ
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            if batch_idx % 10 == 0:
                print(f"  Batch {batch_idx}/{len(train_loader)}: "
                      f"Loss: {loss.item():.4f}, "
                      f"Acc: {correct / total:.4f}")

        train_loss = running_loss / len(train_loader)
        train_acc = correct / total
        train_losses.append(train_loss)
        train_accs.append(train_acc)

        # æµ‹è¯•
        model.eval()
        running_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)

                running_loss += loss.item()
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        test_loss = running_loss / len(test_loader)
        test_acc = correct / total
        test_losses.append(test_loss)
        test_accs.append(test_acc)

        # å­¦ä¹ ç‡è°ƒæ•´
        scheduler.step()

        print(f"\nğŸ“Š Epoch {epoch + 1}/{epochs}:")
        print(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}")
        print(f"  æµ‹è¯•æŸå¤±: {test_loss:.4f}, æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
        print(f"  å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.6f}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if test_acc > best_acc:
            best_acc = test_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'test_acc': test_acc,
                'train_acc': train_acc,
                'best_acc': best_acc
            }, 'resnet50_finetuned_best.pth')
            print(f"  ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œå‡†ç¡®ç‡: {best_acc:.4f}")

    print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
    print(f"æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡: {best_acc:.4f}")

    # å¯è§†åŒ–ç»“æœ
    from visualization import visualize_training_results
    visualize_training_results(
        train_losses, train_accs, test_losses, test_accs,
        save_path='resnet50_finetuning_results.png',
        model_name='ResNet50å¾®è°ƒ'
    )

    return model, train_losses, train_accs, test_losses, test_accs