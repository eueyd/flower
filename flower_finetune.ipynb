{
 "cells": [
  {
   "cell_type": "code",
   "id": "abdf95a9-fbe2-45ee-a5e6-9412b69d0824",
   "metadata": {},
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===================== 全局配置 =====================\n",
    "# 模型/数据保存路径\n",
    "MODEL_PATH = \"best_flower_model.pth\"\n",
    "METRICS_PATH = \"training_metrics.npy\"\n",
    "# 类别映射\n",
    "from flowers102_config import CLASS_NAMES  # 或者直接复制上面提供的CLASS_NAMES列表\n",
    "NUM_CLASSES = 102\n",
    "\n",
    "# 训练参数（全局共享）\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "\n",
    "# ===================== 工具函数 =====================\n",
    "def check_gpu_availability():\n",
    "    \"\"\"验证GPU是否可用并输出详细信息\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"GPU加速已启用！\")\n",
    "        print(f\"GPU设备名称: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU设备数量: {torch.cuda.device_count()}\")\n",
    "        print(f\"CUDA版本: {torch.version.cuda}\")\n",
    "        print(f\"PyTorch CUDA是否可用: {torch.cuda.is_available()}\")\n",
    "        print(\"=\" * 50)\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"警告：未检测到GPU，使用CPU训练/测试（速度较慢）！\")\n",
    "        print(\"=\" * 50)\n",
    "    return device\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"加载并预处理数据集（训练/测试共享）\"\"\"\n",
    "    BASE_DIR = \"flowers102_data\"\n",
    "    TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "    VAL_DIR = os.path.join(BASE_DIR, \"val\")\n",
    "    TEST_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "    # 训练集变换（含数据增强）\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # 测试集变换（无数据增强）\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # 加载数据集\n",
    "    train_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=train_transforms)\n",
    "    val_dataset = datasets.ImageFolder(root=VAL_DIR, transform=test_transforms)\n",
    "    test_dataset = datasets.ImageFolder(root=TEST_DIR, transform=test_transforms)\n",
    "\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    # 打印数据集信息\n",
    "    print(f\"训练集样本数: {len(train_dataset)}\")\n",
    "    print(f\"验证集样本数: {len(val_dataset)}\")\n",
    "    print(f\"测试集样本数: {len(test_dataset)}\")\n",
    "    print(f\"类别数: {NUM_CLASSES}, 类别名称: {CLASS_NAMES}\")\n",
    "\n",
    "    return train_loader, test_loader, train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def build_model(device):\n",
    "    \"\"\"构建迁移学习模型（训练/测试共享）\"\"\"\n",
    "    # 加载预训练的ResNet50\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    # 冻结特征提取层\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # 替换全连接层\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(model.fc.in_features, 1024),  # 从2048降到1024\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(1024, 512),                   # 1024降到512\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, NUM_CLASSES)            # 512降到102（类别数）\n",
    "    )\n",
    "    # 移至指定设备\n",
    "    model = model.to(device)\n",
    "    # 验证模型设备\n",
    "    print(f\"模型已加载至: {next(model.parameters()).device}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_training_metrics(train_losses, train_accs, test_losses, test_accs):\n",
    "    \"\"\"保存训练指标到文件\"\"\"\n",
    "    metrics = {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"train_accs\": train_accs,\n",
    "        \"test_losses\": test_losses,\n",
    "        \"test_accs\": test_accs\n",
    "    }\n",
    "    np.save(METRICS_PATH, metrics)\n",
    "    print(f\"训练指标已保存至: {METRICS_PATH}\")\n",
    "\n",
    "\n",
    "def load_training_metrics():\n",
    "    \"\"\"加载训练指标文件\"\"\"\n",
    "    if not os.path.exists(METRICS_PATH):\n",
    "        raise FileNotFoundError(f\"未找到训练指标文件: {METRICS_PATH}，请先执行训练模式！\")\n",
    "    metrics = np.load(METRICS_PATH, allow_pickle=True).item()\n",
    "    return metrics[\"train_losses\"], metrics[\"train_accs\"], metrics[\"test_losses\"], metrics[\"test_accs\"]\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def visualize_results(train_losses, train_accs, test_losses, test_accs, train_dataset, test_dataset, \n",
    "                     model=None, test_loader=None, device=None, class_names=None, save_dir=\".\"):\n",
    "    \"\"\"增强的可视化分析（子图布局+字体自动检测）\"\"\"\n",
    "    \n",
    "    # 字体自动检测和设置\n",
    "    available_fonts = [f.name for f in mpl.font_manager.fontManager.ttflist]\n",
    "    chinese_fonts = ['WenQuanYi Micro Hei', 'DejaVu Sans', \n",
    "                    'Microsoft YaHei', 'SimHei', 'SimSun', \n",
    "                    'STHeiti', 'STKaiti', 'STSong', \n",
    "                    'Arial Unicode MS', 'Noto Sans CJK SC']\n",
    "    \n",
    "    # 找到第一个可用的中文字体\n",
    "    selected_font = None\n",
    "    for font in chinese_fonts:\n",
    "        if font in available_fonts:\n",
    "            selected_font = font\n",
    "            break\n",
    "    \n",
    "    if selected_font:\n",
    "        # 设置字体\n",
    "        plt.rcParams['font.family'] = [selected_font]\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        print(f\"可视化字体已设置为: {selected_font}\")\n",
    "    else:\n",
    "        print(\"警告：未找到中文字体，使用默认字体\")\n",
    "    \n",
    "    # 计算类别分布（如果提供了class_names）\n",
    "    if class_names:\n",
    "        CLASS_NAMES = class_names\n",
    "        NUM_CLASSES = len(class_names)\n",
    "    else:\n",
    "        CLASS_NAMES = ['pink primrose', 'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea', 'english marigold', 'tiger lily', 'moon orchid', 'bird of paradise', 'monkshood', 'globe thistle', 'snapdragon', \"colt's foot\", 'king protea', 'spear thistle', 'yellow iris', 'globe-flower', 'purple coneflower', 'peruvian lily', 'balloon flower', 'giant white arum lily', 'fire lily', 'pincushion flower', 'fritillary', 'red ginger', 'grape hyacinth', 'corn poppy', 'prince of wales feathers', 'stemless gentian', 'artichoke', 'sweet william', 'carnation', 'garden phlox', 'love in the mist', 'mexican aster', 'alpine sea holly', 'ruby-lipped cattleya', 'cape flower', 'great masterwort', 'siam tulip', 'lenten rose', 'barbeton daisy', 'daffodil', 'sword lily', 'poinsettia', 'bolero deep blue', 'wallflower', 'marigold', 'buttercup', 'oxeye daisy', 'common dandelion', 'petunia', 'wild pansy', 'primula', 'sunflower', 'pelargonium', 'bishop of llandaff', 'gaura', 'geranium', 'orange dahlia', 'pink-yellow dahlia', 'cautleya spicata', 'japanese anemone', 'black-eyed susan', 'silverbush', 'californian poppy', 'osteospermum', 'spring crocus', 'bearded iris', 'windflower', 'tree poppy', 'gazania', 'azalea', 'water lily', 'rose', 'thorn apple', 'morning glory', 'passion flower', 'lotus', 'toad lily', 'anthurium', 'frangipani', 'clematis', 'hibiscus', 'columbine', 'desert-rose', 'tree mallow', 'magnolia', 'cyclamen', 'watercress', 'canna lily', 'hippeastrum', 'bee balm', 'ball moss', 'foxglove', 'bougainvillea', 'camellia', 'mallow', 'mexican petunia', 'bromelia', 'blanket flower', 'trumpet creeper', 'blackberry lily']\n",
    "        NUM_CLASSES = 102\n",
    "    \n",
    "    # 计算训练和测试的类别分布（如果提供了数据集路径）\n",
    "    train_class_counts = []\n",
    "    test_class_counts = []\n",
    "    \n",
    "    try:\n",
    "        TRAIN_DIR = os.path.join(\"flowers102_data\", \"train\")\n",
    "        TEST_DIR = os.path.join(\"flowers102_data\", \"test\")\n",
    "        if os.path.exists(TRAIN_DIR) and os.path.exists(TEST_DIR):\n",
    "            train_class_counts = [len(os.listdir(os.path.join(TRAIN_DIR, cls))) for cls in CLASS_NAMES]\n",
    "            test_class_counts = [len(os.listdir(os.path.join(TEST_DIR, cls))) for cls in CLASS_NAMES]\n",
    "        else:\n",
    "            # 如果没有文件夹，使用随机数据演示\n",
    "            train_class_counts = np.random.randint(50, 100, size=NUM_CLASSES)\n",
    "            test_class_counts = np.random.randint(10, 30, size=NUM_CLASSES)\n",
    "    except:\n",
    "        # 使用示例数据\n",
    "        train_class_counts = np.random.randint(50, 100, size=NUM_CLASSES)\n",
    "        test_class_counts = np.random.randint(10, 30, size=NUM_CLASSES)\n",
    "    \n",
    "    final_train_acc = train_accs[-1] if train_accs else 0\n",
    "    final_test_acc = test_accs[-1] if test_accs else 0\n",
    "    EPOCHS = len(train_losses) if train_losses else 0\n",
    "    \n",
    "    # ====================\n",
    "    # 创建2x2的子图布局\n",
    "    # ====================\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. 损失曲线\n",
    "    ax1 = axes[0, 0]\n",
    "    epochs_range = range(1, EPOCHS + 1)\n",
    "    ax1.plot(epochs_range, train_losses, label=\"训练损失\", marker=\"o\", linewidth=2)\n",
    "    ax1.plot(epochs_range, test_losses, label=\"测试损失\", marker=\"s\", linewidth=2)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('损失值', fontsize=12)\n",
    "    ax1.set_title('训练与测试损失变化', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 添加最后epoch的数值标签\n",
    "    if EPOCHS > 0:\n",
    "        ax1.text(EPOCHS, train_losses[-1], f'{train_losses[-1]:.4f}', \n",
    "                ha='right', va='bottom', fontsize=10)\n",
    "        ax1.text(EPOCHS, test_losses[-1], f'{test_losses[-1]:.4f}', \n",
    "                ha='right', va='top', fontsize=10)\n",
    "    \n",
    "    # 2. 准确率曲线\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(epochs_range, train_accs, label=\"训练准确率\", marker=\"o\", \n",
    "            color=\"green\", linewidth=2)\n",
    "    ax2.plot(epochs_range, test_accs, label=\"测试准确率\", marker=\"s\", \n",
    "            color=\"red\", linewidth=2)\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('准确率', fontsize=12)\n",
    "    ax2.set_title('训练与测试准确率变化', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 1.0)\n",
    "    \n",
    "    # 添加最后epoch的数值标签\n",
    "    if EPOCHS > 0:\n",
    "        ax2.text(EPOCHS, train_accs[-1], f'{train_accs[-1]:.4f}', \n",
    "                ha='right', va='bottom', fontsize=10, color='green')\n",
    "        ax2.text(EPOCHS, test_accs[-1], f'{test_accs[-1]:.4f}', \n",
    "                ha='right', va='top', fontsize=10, color='red')\n",
    "    \n",
    "    # 3. 数据集类别分布\n",
    "    ax3 = axes[1, 0]\n",
    "    x = np.arange(len(CLASS_NAMES))\n",
    "    width = 0.35\n",
    "    \n",
    "    # 创建柱状图\n",
    "    bars1 = ax3.bar(x - width/2, train_class_counts, width, \n",
    "                   label=\"训练集\", color=\"skyblue\", alpha=0.8)\n",
    "    bars2 = ax3.bar(x + width/2, test_class_counts, width, \n",
    "                   label=\"测试集\", color=\"orange\", alpha=0.8)\n",
    "    \n",
    "    ax3.set_xlabel('花卉类别', fontsize=12)\n",
    "    ax3.set_ylabel('样本数量', fontsize=12)\n",
    "    ax3.set_title('数据集类别分布', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels(CLASS_NAMES, rotation=15, ha='right')\n",
    "    ax3.legend()\n",
    "    \n",
    "    # 添加柱状图数值标签\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontsize=4)\n",
    "    \n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontsize=4)\n",
    "    \n",
    "    # 4. 最终准确率对比\n",
    "    ax4 = axes[1, 1]\n",
    "    categories = [\"训练集\", \"测试集\"]\n",
    "    acc_values = [final_train_acc, final_test_acc]\n",
    "    colors = [\"green\", \"red\"]\n",
    "    \n",
    "    bars = ax4.bar(categories, acc_values, color=colors, width=0.6, alpha=0.7)\n",
    "    ax4.set_xlabel('数据集', fontsize=12)\n",
    "    ax4.set_ylabel('准确率', fontsize=12)\n",
    "    ax4.set_title('最终准确率对比', fontsize=14, fontweight='bold')\n",
    "    ax4.set_ylim(0, 1.1)\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 添加柱状图数值标签\n",
    "    for bar, value in zip(bars, acc_values):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{value:.4f}', ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    # 添加整体标题\n",
    "    fig.suptitle('模型训练结果综合分析', fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "    # 如果中文仍然显示有问题，尝试使用英文标签的备选方案\n",
    "    if selected_font is None:\n",
    "        print(\"\\n注意：未找到合适的中文字体，已切换为英文标签\")\n",
    "        # 重新设置标签\n",
    "        axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
    "        axes[0, 0].set_title('Training and Test Loss', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[0, 1].set_ylabel('Accuracy', fontsize=12)\n",
    "        axes[0, 1].set_title('Training and Test Accuracy', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        axes[1, 0].set_xlabel('Flower Class', fontsize=12)\n",
    "        axes[1, 0].set_ylabel('Sample Count', fontsize=12)\n",
    "        axes[1, 0].set_title('Dataset Class Distribution', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        axes[1, 1].set_xlabel('Dataset', fontsize=12)\n",
    "        axes[1, 1].set_ylabel('Accuracy', fontsize=12)\n",
    "        axes[1, 1].set_title('Final Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        fig.suptitle('Model Training Results Analysis', fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # 保存图片到文件\n",
    "    output_path = os.path.join(save_dir, 'training_analysis.png')\n",
    "    \n",
    "    # 保存高分辨率图片\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', \n",
    "               facecolor='white', edgecolor='none')\n",
    "    \n",
    "    # 检查文件是否保存成功\n",
    "    if os.path.exists(output_path):\n",
    "        file_size = os.path.getsize(output_path) / 1024  # 转换为KB\n",
    "        print(f\"✓ 可视化结果已保存为: {output_path}\")\n",
    "        print(f\"✓ 文件大小: {file_size:.2f} KB\")\n",
    "        print(f\"✓ 图片尺寸: {fig.get_size_inches()[0]:.1f} x {fig.get_size_inches()[1]:.1f} 英寸\")\n",
    "        print(f\"✓ DPI: 300\")\n",
    "        print(f\"✓ 格式: PNG\")\n",
    "    else:\n",
    "        print(\"✗ 图片保存失败\")\n",
    "    \n",
    "    # 显示图表\n",
    "    plt.show()\n",
    "    \n",
    "    # 如果有模型和测试数据，绘制混淆矩阵\n",
    "    if model is not None and test_loader is not None and device is not None:\n",
    "        plot_confusion_matrix(model, test_loader, device, class_names, save_dir)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "\n",
    "# 增强的混淆矩阵绘制函数\n",
    "def plot_confusion_matrix(model, test_loader, device, class_names=None, save_dir=\".\"):\n",
    "    \"\"\"绘制混淆矩阵图\"\"\"\n",
    "    \n",
    "    # 字体设置（复用之前的逻辑）\n",
    "    available_fonts = [f.name for f in mpl.font_manager.fontManager.ttflist]\n",
    "    chinese_fonts = ['WenQuanYi Micro Hei', 'DejaVu Sans', \n",
    "                    'Microsoft YaHei', 'SimHei', 'SimSun', \n",
    "                    'STHeiti', 'STKaiti', 'STSong']\n",
    "    \n",
    "    selected_font = None\n",
    "    for font in chinese_fonts:\n",
    "        if font in available_fonts:\n",
    "            selected_font = font\n",
    "            break\n",
    "    \n",
    "    if selected_font:\n",
    "        plt.rcParams['font.family'] = [selected_font]\n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "    else:\n",
    "        print(\"警告：混淆矩阵使用默认字体\")\n",
    "    \n",
    "    # 设置类别名称\n",
    "    if class_names is None:\n",
    "        class_names = [f\"Class {i}\" for i in range(102)]  # 默认10个类别\n",
    "    \n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    # 初始化混淆矩阵\n",
    "    conf_matrix = np.zeros((num_classes, num_classes))\n",
    "    \n",
    "    # 收集预测结果\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # 更新混淆矩阵\n",
    "            for t, p in zip(labels.cpu().numpy(), preds.cpu().numpy()):\n",
    "                conf_matrix[t, p] += 1\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    # 计算整体准确率\n",
    "    correct = np.sum(np.diag(conf_matrix))\n",
    "    total = np.sum(conf_matrix)\n",
    "    overall_acc = correct / total if total > 0 else 0\n",
    "    \n",
    "    # 计算每个类别的准确率\n",
    "    class_acc = np.zeros(num_classes)\n",
    "    for i in range(num_classes):\n",
    "        class_total = np.sum(conf_matrix[i, :])\n",
    "        if class_total > 0:\n",
    "            class_acc[i] = conf_matrix[i, i] / class_total\n",
    "    \n",
    "    # 创建带有两个子图的图形\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    # 1. 混淆矩阵热力图\n",
    "    ax1 = axes[0]\n",
    "    # 归一化混淆矩阵（按行）\n",
    "    conf_matrix_norm = conf_matrix / conf_matrix.sum(axis=1, keepdims=True)\n",
    "    conf_matrix_norm = np.nan_to_num(conf_matrix_norm)  # 处理除零情况\n",
    "    \n",
    "    # 热力图展示\n",
    "    im = ax1.imshow(conf_matrix_norm, cmap='Blues', aspect='auto')\n",
    "    \n",
    "    ax1.set_title(f'混淆矩阵 (整体准确率: {overall_acc:.2%})', fontsize=16, fontweight='bold')\n",
    "    plt.colorbar(im, ax=ax1, label='归一化值')\n",
    "    ax1.set_xlabel('预测类别', fontsize=14)\n",
    "    ax1.set_ylabel('真实类别', fontsize=14)\n",
    "    \n",
    "    # 设置刻度标签\n",
    "    ax1.set_xticks(np.arange(num_classes))\n",
    "    ax1.set_yticks(np.arange(num_classes))\n",
    "    ax1.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "    ax1.set_yticklabels(class_names)\n",
    "    \n",
    "    # 添加数值标注\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            if conf_matrix[i, j] > 0:  # 只显示非零值\n",
    "                text_color = 'white' if conf_matrix_norm[i, j] > 0.5 else 'black'\n",
    "                ax1.text(j, i, f'{conf_matrix_norm[i, j]:.2f}\\n({int(conf_matrix[i, j])})',\n",
    "                        ha='center', va='center', \n",
    "                        color=text_color, fontsize=4)\n",
    "    \n",
    "    # 2. 类别准确率柱状图\n",
    "    ax2 = axes[1]\n",
    "    x_pos = np.arange(num_classes)\n",
    "    bars = ax2.bar(x_pos, class_acc, color='steelblue', alpha=0.7)\n",
    "    \n",
    "    ax2.set_xlabel('类别', fontsize=14)\n",
    "    ax2.set_ylabel('准确率', fontsize=14)\n",
    "    ax2.set_title('各类别准确率', fontsize=16, fontweight='bold')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "    ax2.set_ylim(0, 1.1)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 添加柱状图数值标签\n",
    "    for bar, acc in zip(bars, class_acc):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{acc:.2%}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # 添加平均线\n",
    "    ax2.axhline(y=overall_acc, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "    ax2.text(num_classes-0.5, overall_acc+0.02, f'平均: {overall_acc:.2%}', \n",
    "             color='red', fontsize=11, ha='right')\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图片\n",
    "    output_path = os.path.join(save_dir, 'confusion_matrix.png')\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', \n",
    "               facecolor='white', edgecolor='none')\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        file_size = os.path.getsize(output_path) / 1024\n",
    "        print(f\"✓ 混淆矩阵已保存为: {output_path}\")\n",
    "        print(f\"✓ 文件大小: {file_size:.2f} KB\")\n",
    "    else:\n",
    "        print(\"✗ 混淆矩阵保存失败\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # 打印详细的准确率信息\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"模型性能详细分析\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"整体准确率: {overall_acc:.2%} ({correct}/{total})\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"{'类别':<15} {'准确率':<12} {'正确数/总数':<15}\")\n",
    "    print(f\"{'-'*50}\")\n",
    "    \n",
    "    for i, (cls_name, acc) in enumerate(zip(class_names, class_acc)):\n",
    "        class_total = np.sum(conf_matrix[i, :])\n",
    "        class_correct = conf_matrix[i, i]\n",
    "        print(f\"{cls_name:<15} {acc:<12.2%} {int(class_correct):<4}/{int(class_total):<4}\")\n",
    "    \n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    return conf_matrix, overall_acc\n",
    "# ===================== 训练/测试核心逻辑 =====================\n",
    "def train_model(device):\n",
    "    \"\"\"重新训练模型并保存结果\"\"\"\n",
    "    # 加载数据\n",
    "    train_loader, test_loader, train_dataset, test_dataset = load_data()\n",
    "    # 构建模型\n",
    "    model = build_model(device)\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    # 训练指标记录\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    best_test_acc = 0.0\n",
    "\n",
    "    # 开始训练\n",
    "    print(\"\\n========== 开始训练 ==========\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        # 训练一个epoch\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS} [Train]\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 统计\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            pbar.set_postfix({\"loss\": running_loss / total, \"acc\": correct / total})\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # 验证\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(test_loader, desc=\"Validation\")\n",
    "            for images, labels in pbar:\n",
    "                images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                pbar.set_postfix({\"loss\": running_loss / total, \"acc\": correct / total})\n",
    "        test_loss = running_loss / len(test_loader.dataset)\n",
    "        test_acc = correct / total\n",
    "\n",
    "        # 学习率衰减\n",
    "        scheduler.step()\n",
    "\n",
    "        # 记录指标\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "        # 保存最优模型\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(f\"保存最优模型，测试准确率: {best_test_acc:.4f}\")\n",
    "\n",
    "        # 打印epoch结果\n",
    "        print(f\"Epoch {epoch + 1} | 训练损失: {train_loss:.4f}, 训练准确率: {train_acc:.4f}\")\n",
    "        print(f\"          | 测试损失: {test_loss:.4f}, 测试准确率: {test_acc:.4f}\\n\")\n",
    "\n",
    "    # 保存训练指标\n",
    "    save_training_metrics(train_losses, train_accs, test_losses, test_accs)\n",
    "    print(f\"训练完成！最优测试准确率: {best_test_acc:.4f}\")\n",
    "\n",
    "    # 可视化结果\n",
    "    visualize_results(train_losses, train_accs, test_losses, test_accs, train_dataset, test_dataset)\n",
    "\n",
    "    # 新增：训练完成后绘制混淆矩阵\n",
    "    plot_confusion_matrix(model, test_loader, device)\n",
    "\n",
    "    # 最终评估\n",
    "    evaluate_model(device, test_loader)\n",
    "\n",
    "\n",
    "def evaluate_model(device, test_loader=None):\n",
    "    \"\"\"仅加载模型测试并输出结果\"\"\"\n",
    "    # 加载数据（若未传入test_loader）\n",
    "    if test_loader is None:\n",
    "        _, test_loader, _, _ = load_data()\n",
    "\n",
    "    # 检查模型文件\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"未找到模型文件: {MODEL_PATH}，请先执行训练模式！\")\n",
    "\n",
    "    # 构建并加载模型\n",
    "    model = build_model(device)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.eval()\n",
    "\n",
    "    # 测试集评估\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = [0] * NUM_CLASSES\n",
    "    class_total = [0] * NUM_CLASSES\n",
    "\n",
    "    print(\"\\n========== 开始测试 ==========\")\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_loader, desc=\"Testing\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 整体指标\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # 分类别指标\n",
    "            for label, pred in zip(labels, predicted):\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "                class_total[label] += 1\n",
    "\n",
    "            pbar.set_postfix({\"loss\": running_loss / total, \"acc\": correct / total})\n",
    "\n",
    "    # 计算最终指标\n",
    "    final_loss = running_loss / len(test_loader.dataset)\n",
    "    final_acc = correct / total\n",
    "\n",
    "    # 打印结果\n",
    "    print(f\"\\n测试完成！\")\n",
    "    print(f\"整体测试损失: {final_loss:.4f}, 整体测试准确率: {final_acc:.4f}\")\n",
    "    print(\"\\n各类别准确率:\")\n",
    "    for i in range(NUM_CLASSES):\n",
    "        acc = class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
    "        print(f\"{CLASS_NAMES[i]}: {acc:.4f} (正确数: {class_correct[i]}, 总数: {class_total[i]})\")\n",
    "\n",
    "    # 加载训练指标并可视化\n",
    "    try:\n",
    "        train_losses, train_accs, test_losses, test_accs = load_training_metrics()\n",
    "        _, _, train_dataset, test_dataset = load_data()\n",
    "        visualize_results(train_losses, train_accs, test_losses, test_accs, train_dataset, test_dataset)\n",
    "\n",
    "        # 新增：测试完成后绘制混淆矩阵\n",
    "        plot_confusion_matrix(model, test_loader, device)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n警告：{e}，仅展示测试结果，跳过可视化！\")\n",
    "\n",
    "\n",
    "# ===================== 主程序入口 =====================\n",
    "if __name__ == '__main__':\n",
    "    # 设备初始化\n",
    "    device = check_gpu_availability()\n",
    "\n",
    "    # 模式选择\n",
    "    print(\"\\n========== 花卉分类模型 ==========\")\n",
    "    print(\"请选择运行模式：\")\n",
    "    print(\"1. 重新训练模型（会覆盖原有模型和训练指标）\")\n",
    "    print(\"2. 仅测试（使用已训练的模型）\")\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"输入选择（1/2）：\"))\n",
    "            if choice in [1, 2]:\n",
    "                break\n",
    "            else:\n",
    "                print(\"请输入1或2！\")\n",
    "        except ValueError:\n",
    "            print(\"请输入有效的数字（1/2）！\")\n",
    "\n",
    "    # 执行对应模式\n",
    "    if choice == 1:\n",
    "        train_model(device)\n",
    "    elif choice == 2:\n",
    "        evaluate_model(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b855466f6c84cbc2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRL Comparison",
   "language": "python",
   "name": "drl_comparison"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
