{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f27b15aa-fb19-4d75-a1fa-2a94bbc4abf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_gpu_availability' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 533\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# ===================== 其他辅助函数保持不变 =====================\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;66;03m# （check_gpu_availability, load_data, save_training_metrics, \u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# load_training_metrics, visualize_results, plot_confusion_matrix）\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m \n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# ===================== 主程序入口保持不变 =====================\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 533\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_gpu_availability\u001b[49m()\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m========== 细粒度花卉分类模型（双路径架构）==========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m架构特点:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'check_gpu_availability' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=========================== 新架构说明 ===========================\n",
    "双路径细粒度识别网络：\n",
    "1. 全局路径：提取整体特征\n",
    "2. 局部路径：自动发现2个判别性区域，提取局部特征\n",
    "3. 自适应融合：动态加权融合全局+局部特征\n",
    "4. 多粒度监督：主损失 + 辅助损失\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===================== 全局配置 =====================\n",
    "MODEL_PATH = \"best_flower_model.pth\"\n",
    "METRICS_PATH = \"training_metrics.npy\"\n",
    "CLASS_NAMES = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "IMAGE_SIZE = (224, 224)\n",
    "NUM_REGIONS = 2  # 提取2个局部区域\n",
    "\n",
    "\n",
    "# ===================== 新模型组件 =====================\n",
    "class RegionProposalModule(nn.Module):\n",
    "    \"\"\"区域提议模块：生成注意力图，定位判别性区域\"\"\"\n",
    "    def __init__(self, in_channels, num_regions):\n",
    "        super().__init__()\n",
    "        self.num_regions = num_regions\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, num_regions, kernel_size=1),\n",
    "            nn.Softmax(dim=1)  # 每个位置的概率分布\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [B, C, H, W]\n",
    "        attention_maps = self.conv(x)  # [B, num_regions, H, W]\n",
    "        return attention_maps\n",
    "\n",
    "\n",
    "class LocalFeatureExtractor(nn.Module):\n",
    "    \"\"\"局部特征提取器：从注意力图指定的区域提取特征\"\"\"\n",
    "    def __init__(self, backbone, feature_dim):\n",
    "        super().__init__()\n",
    "        # 使用backbone的前几层作为局部特征提取器\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-2])\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(feature_dim, 256)  # 将局部特征压缩\n",
    "    \n",
    "    def forward(self, x, attention_map):\n",
    "        # x: [B, C, H, W], attention_map: [B, 1, H, W]\n",
    "        # 应用注意力图（广播）\n",
    "        weighted_x = x * attention_map.unsqueeze(1)  # [B, C, H, W]\n",
    "        \n",
    "        # 提取局部特征\n",
    "        features = self.backbone(weighted_x)\n",
    "        pooled = self.global_pool(features).squeeze(-1).squeeze(-1)  # [B, feature_dim]\n",
    "        compressed = self.fc(pooled)  # [B, 256]\n",
    "        return compressed\n",
    "\n",
    "\n",
    "class AdaptiveFusionModule(nn.Module):\n",
    "    \"\"\"自适应融合模块：动态加权融合全局和局部特征\"\"\"\n",
    "    def __init__(self, global_dim, local_dim, num_regions):\n",
    "        super().__init__()\n",
    "        total_dim = global_dim + local_dim * num_regions\n",
    "        self.weight_generator = nn.Sequential(\n",
    "            nn.Linear(total_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1 + num_regions),  # 全局权重 + 各局部权重\n",
    "            nn.Softmax(dim=1)  # 权重和为1\n",
    "        )\n",
    "    \n",
    "    def forward(self, global_feat, local_feats):\n",
    "        # global_feat: [B, global_dim]\n",
    "        # local_feats: list of [B, local_dim]\n",
    "        batch_size = global_feat.size(0)\n",
    "        \n",
    "        # 拼接所有特征\n",
    "        all_feats = [global_feat] + local_feats\n",
    "        concat_feats = torch.cat(all_feats, dim=1)  # [B, total_dim]\n",
    "        \n",
    "        # 生成自适应权重\n",
    "        weights = self.weight_generator(concat_feats)  # [B, 1+num_regions]\n",
    "        \n",
    "        # 按权重融合\n",
    "        weighted_global = global_feat * weights[:, 0:1]\n",
    "        weighted_local = sum(local_feats[i] * weights[:, i+1:i+2] \n",
    "                           for i in range(len(local_feats)))\n",
    "        \n",
    "        fused_feature = weighted_global + weighted_local\n",
    "        return fused_feature, weights\n",
    "\n",
    "\n",
    "class FineGrainedFlowerModel(nn.Module):\n",
    "    \"\"\"细粒度花卉分类模型\"\"\"\n",
    "    def __init__(self, num_classes, num_regions=2):\n",
    "        super().__init__()\n",
    "        self.num_regions = num_regions\n",
    "        \n",
    "        # 骨干网络（ResNet50）\n",
    "        backbone = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # 全局特征提取器（使用全网络）\n",
    "        self.global_extractor = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        \n",
    "        # 中间层特征提取器（用于区域提议）\n",
    "        self.mid_feature_extractor = nn.Sequential(*list(backbone.children())[:7])\n",
    "        \n",
    "        # 区域提议模块\n",
    "        self.region_proposal = RegionProposalModule(1024, num_regions)\n",
    "        \n",
    "        # 局部特征提取器\n",
    "        self.local_extractors = nn.ModuleList([\n",
    "            LocalFeatureExtractor(backbone, 2048) for _ in range(num_regions)\n",
    "        ])\n",
    "        \n",
    "        # 自适应融合模块\n",
    "        self.fusion_module = AdaptiveFusionModule(\n",
    "            global_dim=2048, \n",
    "            local_dim=256, \n",
    "            num_regions=num_regions\n",
    "        )\n",
    "        \n",
    "        # 分类器\n",
    "        self.global_classifier = nn.Linear(2048, num_classes)  # 辅助分类器\n",
    "        self.local_classifiers = nn.ModuleList([\n",
    "            nn.Linear(256, num_classes) for _ in range(num_regions)  # 局部辅助分类器\n",
    "        ])\n",
    "        self.final_classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # 冻结骨干网络的前几层\n",
    "        for param in list(self.mid_feature_extractor.parameters())[:100]:\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # ===== 全局路径 =====\n",
    "        global_feat = self.global_extractor(x)  # [B, 2048, 1, 1]\n",
    "        global_feat_flat = global_feat.view(batch_size, -1)  # [B, 2048]\n",
    "        \n",
    "        # ===== 局部路径 =====\n",
    "        # 提取中层特征用于区域提议\n",
    "        mid_features = self.mid_feature_extractor(x)  # [B, 1024, 14, 14]\n",
    "        \n",
    "        # 生成区域注意力图\n",
    "        attention_maps = self.region_proposal(mid_features)  # [B, num_regions, 14, 14]\n",
    "        \n",
    "        # 提取局部特征\n",
    "        local_feats = []\n",
    "        local_features_raw = self.global_extractor(x)  # 重用全局特征提取\n",
    "        local_features_raw = local_features_raw.view(batch_size, -1)  # [B, 2048]\n",
    "        \n",
    "        for i in range(self.num_regions):\n",
    "            # 使用注意力图加权原始输入\n",
    "            att_map = attention_maps[:, i:i+1]  # [B, 1, 14, 14]\n",
    "            att_map_upsampled = F.interpolate(\n",
    "                att_map, size=x.shape[2:], mode='bilinear', align_corners=False\n",
    "            )\n",
    "            \n",
    "            # 加权输入图像\n",
    "            weighted_input = x * att_map_upsampled\n",
    "            \n",
    "            # 提取该区域的局部特征\n",
    "            local_feat = self.local_extractors[i](weighted_input, att_map_upsampled)\n",
    "            local_feats.append(local_feat)\n",
    "        \n",
    "        # ===== 自适应融合 =====\n",
    "        fused_feature, fusion_weights = self.fusion_module(global_feat_flat, local_feats)\n",
    "        \n",
    "        # ===== 分类输出 =====\n",
    "        global_logits = self.global_classifier(global_feat_flat)\n",
    "        local_logits = [classifier(feat) for classifier, feat in zip(self.local_classifiers, local_feats)]\n",
    "        final_logits = self.final_classifier(fused_feature)\n",
    "        \n",
    "        # ===== 注意力图上采样（用于可视化） =====\n",
    "        attention_maps_vis = F.interpolate(\n",
    "            attention_maps, size=x.shape[2:], mode='bilinear', align_corners=False\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'final_logits': final_logits,\n",
    "            'global_logits': global_logits,\n",
    "            'local_logits': local_logits,\n",
    "            'attention_maps': attention_maps_vis,\n",
    "            'fusion_weights': fusion_weights,\n",
    "            'fused_feature': fused_feature\n",
    "        }\n",
    "\n",
    "\n",
    "# ===================== 修改后的模型构建函数 =====================\n",
    "def build_model(device):\n",
    "    \"\"\"构建双路径细粒度模型\"\"\"\n",
    "    model = FineGrainedFlowerModel(\n",
    "        num_classes=NUM_CLASSES,\n",
    "        num_regions=NUM_REGIONS\n",
    "    )\n",
    "    \n",
    "    # 移至指定设备\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 打印模型信息\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"模型已加载至: {next(model.parameters()).device}\")\n",
    "    print(f\"总参数量: {total_params:,}\")\n",
    "    print(f\"可训练参数量: {trainable_params:,}\")\n",
    "    print(f\"使用区域数量: {NUM_REGIONS}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ===================== 修改后的训练逻辑 =====================\n",
    "def train_model(device):\n",
    "    \"\"\"重新训练双路径模型\"\"\"\n",
    "    # 加载数据\n",
    "    train_loader, test_loader, train_dataset, test_dataset = load_data()\n",
    "    \n",
    "    # 构建双路径模型\n",
    "    model = build_model(device)\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), \n",
    "        lr=LEARNING_RATE\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    \n",
    "    # 训练指标记录\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    best_test_acc = 0.0\n",
    "    \n",
    "    # 辅助损失权重\n",
    "    lambda_global = 0.3  # 全局分支损失权重\n",
    "    lambda_local = 0.2   # 每个局部分支损失权重\n",
    "    \n",
    "    print(f\"\\n========== 开始训练（双路径架构）==========\")\n",
    "    print(f\"辅助损失权重: 全局={lambda_global}, 每个局部={lambda_local}\")\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # ===== 训练阶段 =====\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS} [Train]\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "            final_logits = outputs['final_logits']\n",
    "            global_logits = outputs['global_logits']\n",
    "            local_logits = outputs['local_logits']\n",
    "            \n",
    "            # 计算多粒度损失\n",
    "            loss_final = criterion(final_logits, labels)\n",
    "            loss_global = criterion(global_logits, labels)\n",
    "            loss_local = sum(criterion(logits, labels) for logits in local_logits) / len(local_logits)\n",
    "            \n",
    "            # 总损失（加权和）\n",
    "            total_loss = loss_final + lambda_global * loss_global + lambda_local * loss_local\n",
    "            \n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 统计\n",
    "            running_loss += total_loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(final_logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                \"loss\": running_loss / total,\n",
    "                \"acc\": correct / total,\n",
    "                \"fusion_w\": outputs['fusion_weights'][0].cpu().detach().numpy().round(2)\n",
    "            })\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = correct / total\n",
    "        \n",
    "        # ===== 验证阶段 =====\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(test_loader, desc=\"Validation\")\n",
    "            for images, labels in pbar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                final_logits = outputs['final_logits']\n",
    "                global_logits = outputs['global_logits']\n",
    "                local_logits = outputs['local_logits']\n",
    "                \n",
    "                # 计算验证损失（仅用于监控，不反向传播）\n",
    "                loss_final = criterion(final_logits, labels)\n",
    "                loss_global = criterion(global_logits, labels)\n",
    "                loss_local = sum(criterion(logits, labels) for logits in local_logits) / len(local_logits)\n",
    "                total_loss = loss_final + lambda_global * loss_global + lambda_local * loss_local\n",
    "                \n",
    "                running_loss += total_loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(final_logits, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    \"loss\": running_loss / total,\n",
    "                    \"acc\": correct / total\n",
    "                })\n",
    "        \n",
    "        test_loss = running_loss / len(test_loader.dataset)\n",
    "        test_acc = correct / total\n",
    "        \n",
    "        # 学习率衰减\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 记录指标\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        # 保存最优模型\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'best_test_acc': best_test_acc,\n",
    "                'epoch': epoch\n",
    "            }, MODEL_PATH)\n",
    "            print(f\"保存最优模型，测试准确率: {best_test_acc:.4f}\")\n",
    "        \n",
    "        # 打印epoch结果\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        print(f\"  训练损失: {train_loss:.4f}, 训练准确率: {train_acc:.4f}\")\n",
    "        print(f\"  测试损失: {test_loss:.4f}, 测试准确率: {test_acc:.4f}\")\n",
    "        print(f\"  融合权重示例: {outputs['fusion_weights'][0].cpu().numpy().round(3)}\\n\")\n",
    "    \n",
    "    # 保存训练指标\n",
    "    save_training_metrics(train_losses, train_accs, test_losses, test_accs)\n",
    "    print(f\"训练完成！最优测试准确率: {best_test_acc:.4f}\")\n",
    "    \n",
    "    # 可视化结果\n",
    "    visualize_results(train_losses, train_accs, test_losses, test_accs, train_dataset, test_dataset)\n",
    "    \n",
    "    # 可视化注意力图（新增）\n",
    "    visualize_attention_maps(model, test_loader, device)\n",
    "    \n",
    "    # 绘制混淆矩阵\n",
    "    plot_confusion_matrix(model, test_loader, device)\n",
    "    \n",
    "    # 最终评估\n",
    "    evaluate_model(device, test_loader)\n",
    "\n",
    "\n",
    "def visualize_attention_maps(model, test_loader, device, num_samples=5):\n",
    "    \"\"\"可视化区域提议模块的注意力图\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        images, labels = next(iter(test_loader))\n",
    "        images = images[:num_samples].to(device)\n",
    "        labels = labels[:num_samples]\n",
    "        \n",
    "        outputs = model(images)\n",
    "        attention_maps = outputs['attention_maps'].cpu()  # [B, num_regions, H, W]\n",
    "        fusion_weights = outputs['fusion_weights'].cpu()  # [B, 1+num_regions]\n",
    "        \n",
    "        fig, axes = plt.subplots(num_samples, NUM_REGIONS + 2, figsize=(15, 3*num_samples))\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # 原始图像\n",
    "            img = images[i].cpu()\n",
    "            img = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "            img = img + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "            img = img.clamp(0, 1).permute(1, 2, 0).numpy()\n",
    "            \n",
    "            axes[i, 0].imshow(img)\n",
    "            axes[i, 0].set_title(f\"原始图像\\n{CLASS_NAMES[labels[i]]}\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # 各个区域的注意力图\n",
    "            for j in range(NUM_REGIONS):\n",
    "                att_map = attention_maps[i, j].numpy()\n",
    "                axes[i, j+1].imshow(att_map, cmap='hot')\n",
    "                weight = fusion_weights[i, j+1].item()\n",
    "                axes[i, j+1].set_title(f\"区域{j+1}\\n权重: {weight:.3f}\")\n",
    "                axes[i, j+1].axis('off')\n",
    "            \n",
    "            # 融合后的注意力图\n",
    "            combined_att = attention_maps[i].sum(dim=0).numpy()\n",
    "            axes[i, -1].imshow(combined_att, cmap='hot')\n",
    "            axes[i, -1].set_title(\"融合注意力\")\n",
    "            axes[i, -1].axis('off')\n",
    "        \n",
    "        plt.suptitle(\"区域注意力可视化\", fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"attention_visualization.png\", dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ===================== 修改后的评估函数 =====================\n",
    "def evaluate_model(device, test_loader=None):\n",
    "    \"\"\"测试双路径模型\"\"\"\n",
    "    if test_loader is None:\n",
    "        _, test_loader, _, _ = load_data()\n",
    "    \n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"未找到模型文件: {MODEL_PATH}，请先执行训练模式！\")\n",
    "    \n",
    "    # 构建模型\n",
    "    model = build_model(device)\n",
    "    \n",
    "    # 加载模型权重\n",
    "    checkpoint = torch.load(MODEL_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # 测试评估\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = [0] * NUM_CLASSES\n",
    "    class_total = [0] * NUM_CLASSES\n",
    "    \n",
    "    print(f\"\\n========== 开始测试（双路径架构）==========\")\n",
    "    \n",
    "    # 收集融合权重用于分析\n",
    "    all_fusion_weights = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_loader, desc=\"Testing\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            final_logits = outputs['final_logits']\n",
    "            \n",
    "            # 收集融合权重\n",
    "            all_fusion_weights.append(outputs['fusion_weights'].cpu())\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(final_logits, labels)\n",
    "            \n",
    "            # 统计指标\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(final_logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            for label, pred in zip(labels, predicted):\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "                class_total[label] += 1\n",
    "            \n",
    "            pbar.set_postfix({\"loss\": running_loss / total, \"acc\": correct / total})\n",
    "    \n",
    "    # 计算最终指标\n",
    "    final_loss = running_loss / len(test_loader.dataset)\n",
    "    final_acc = correct / total\n",
    "    \n",
    "    # 分析融合权重\n",
    "    all_fusion_weights = torch.cat(all_fusion_weights, dim=0)\n",
    "    avg_weights = all_fusion_weights.mean(dim=0).numpy()\n",
    "    \n",
    "    print(f\"\\n测试完成！\")\n",
    "    print(f\"整体测试损失: {final_loss:.4f}, 整体测试准确率: {final_acc:.4f}\")\n",
    "    print(f\"平均融合权重: 全局={avg_weights[0]:.3f}, \" + \n",
    "          \", \".join([f\"区域{i+1}={avg_weights[i+1]:.3f}\" for i in range(NUM_REGIONS)]))\n",
    "    \n",
    "    print(\"\\n各类别准确率:\")\n",
    "    for i in range(NUM_CLASSES):\n",
    "        acc = class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
    "        print(f\"{CLASS_NAMES[i]}: {acc:.4f} (正确数: {class_correct[i]}, 总数: {class_total[i]})\")\n",
    "    \n",
    "    # 可视化结果\n",
    "    try:\n",
    "        train_losses, train_accs, test_losses, test_accs = load_training_metrics()\n",
    "        _, _, train_dataset, test_dataset = load_data()\n",
    "        visualize_results(train_losses, train_accs, test_losses, test_accs, train_dataset, test_dataset)\n",
    "        \n",
    "        # 可视化注意力图\n",
    "        visualize_attention_maps(model, test_loader, device)\n",
    "        \n",
    "        # 绘制混淆矩阵\n",
    "        plot_confusion_matrix(model, test_loader, device)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n警告：{e}，仅展示测试结果，跳过可视化！\")\n",
    "\n",
    "\n",
    "# ===================== 其他辅助函数保持不变 =====================\n",
    "# （check_gpu_availability, load_data, save_training_metrics, \n",
    "# load_training_metrics, visualize_results, plot_confusion_matrix）\n",
    "\n",
    "# ... [保持原有的辅助函数不变，只修改上面提到的部分] ...\n",
    "\n",
    "# ===================== 主程序入口保持不变 =====================\n",
    "if __name__ == '__main__':\n",
    "    device = check_gpu_availability()\n",
    "    \n",
    "    print(\"\\n========== 细粒度花卉分类模型（双路径架构）==========\")\n",
    "    print(f\"架构特点:\")\n",
    "    print(f\"1. 全局路径 + {NUM_REGIONS}个局部路径\")\n",
    "    print(f\"2. 自适应融合模块\")\n",
    "    print(f\"3. 多粒度监督训练\")\n",
    "    \n",
    "    print(\"\\n请选择运行模式：\")\n",
    "    print(\"1. 重新训练模型（双路径架构）\")\n",
    "    print(\"2. 仅测试（使用已训练的双路径模型）\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"输入选择（1/2）：\"))\n",
    "            if choice in [1, 2]:\n",
    "                break\n",
    "            else:\n",
    "                print(\"请输入1或2！\")\n",
    "        except ValueError:\n",
    "            print(\"请输入有效的数字（1/2）！\")\n",
    "    \n",
    "    if choice == 1:\n",
    "        train_model(device)\n",
    "    elif choice == 2:\n",
    "        evaluate_model(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5b133-3d5a-4ac3-82d8-76ef7aac224a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052bcf72-66fe-43a2-996a-dbf68ec49d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRL Comparison",
   "language": "python",
   "name": "drl_comparison"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
